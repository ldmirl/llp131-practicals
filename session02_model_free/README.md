## Pratical Description

| Notebook                                         | Colab                                                                                                                                                                                                    |
| ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [`Q-Learning`](./qlearning.ipynb)                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lulmil/llp131-practicals/blob/master/session02_model_free/qlearning.ipynb)         |
| [`Expected-SARSA`](./expected_sarsa.ipynb)       | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lulmil/llp131-practicals/blob/master/session02_model_free/expected_sarsa.ipynb)    |
| [`Experience Replay`](./experience_replay.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lulmil/llp131-practicals/blob/master/session02_model_free/experience_replay.ipynb) |

The main practical is `qlearning.ipynb` and `expected_sarsa.ipynb` notebooks in this folder. It has no requirements besides the most basic data science libraries (e.g. numpy, matplotlib, pandas) so you should be able to run it locally.

The extra practical `experience_replay.ipynb` is there to get you tinkering with Experience Replay before tackling Deep Reinforcement Learning (DRL) next session.
